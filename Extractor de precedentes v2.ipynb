{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código redes de sentencias de la Corte Constitucional\n",
    "\n",
    "    Autores: Andrés Felipe Patiño y Juan Carlos Rodríguez Raga\n",
    "    Universidad de los Andes\n",
    "    2020-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paquetes necesarios para la extracción de sentencias\n",
    "import os\n",
    "import requests\n",
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from random import sample\n",
    "# paquetes necesarios para constituir la red\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import infomap\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de sentencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carpeta para guardar sentencias\n",
    "folder_location = './sentencias_completas'\n",
    "if not os.path.exists(folder_location):\n",
    "    os.mkdir(folder_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listas necesarias para extraer las sentencias de la página \n",
    "añosn = ['92','93','94','95','96','97','98','99']\n",
    "añosd = ['00','01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20']\n",
    "pages = ['0', '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extractor de sentencias por año\n",
    "# si no funciona, agregar la función try\n",
    "urls=[]\n",
    "for i in añosn:\n",
    "    for p in pages:\n",
    "        url= \"https://www.corteconstitucional.gov.co/relatoria/radicador/buscar.php?ponente=&demandado=&Sentencia=&Tipo=Sentencias&proceso=&busqueda=&conector=AND&segundotema=&anios=\"+str(i)+\"&pg=\"+str(p)+\"&vs=0&accion=Buscar\"\n",
    "        urls.append(url)\n",
    "links=[]\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    results = soup.find_all('td', attrs={'width': '100%'})\n",
    "    for result in results:\n",
    "        hipervinculo=result.find(\"a\")\n",
    "        if hipervinculo != None:\n",
    "            link=hipervinculo.get(\"href\")\n",
    "            link_completo=urllib.parse.urljoin(url,link)\n",
    "            links.append(link_completo)\n",
    "            filename=os.path.join(folder_location,link.split('/')[-1])\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(requests.get(link_completo).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "for i in añosd:\n",
    "    for p in pages:\n",
    "        url= \"https://www.corteconstitucional.gov.co/relatoria/radicador/buscar.php?ponente=&demandado=&Sentencia=&Tipo=Sentencias&proceso=&busqueda=&conector=AND&segundotema=&anios=\"+str(i)+\"&pg=\"+str(p)+\"&vs=0&accion=Buscar\"\n",
    "        urls.append(url)\n",
    "links=[]\n",
    "for url in urls:\n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            results = soup.find_all('td', attrs={'width': '100%'})\n",
    "            for result in results:\n",
    "                hipervinculo=result.find(\"a\")\n",
    "                if hipervinculo != None:\n",
    "                    link=hipervinculo.get(\"href\")\n",
    "                    link_completo=urllib.parse.urljoin(url,link)\n",
    "                    links.append(link_completo)\n",
    "                    filename=os.path.join(folder_location,link.split('/')[-1])\n",
    "                    with open(filename, 'wb') as f:\n",
    "                        f.write(requests.get(link_completo).content)\n",
    "        except requests.ConnectionError as e:\n",
    "            print(\"OOPS!! Connection Error. Make sure you are connected to Internet. Technical Details given below.\\n\")\n",
    "            print(str(e))\n",
    "            continue\n",
    "        except requests.Timeout as e:\n",
    "            print(\"OOPS!! Timeout Error\")\n",
    "            print(str(e))\n",
    "            continue\n",
    "        except requests.RequestException as e:\n",
    "            print(\"OOPS!! General Error\")\n",
    "            print(str(e))\n",
    "            continue\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Someone closed the program\")\n",
    "            continue\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código para extraer sólamente una muestra (debe reemplazarse en el cuadro anterior)\n",
    "#muestra = sample(links,1022)\n",
    "#for link in muestra:\n",
    " #   filename=os.path.join(folder_location,link.split('/')[-1])\n",
    "  #  with open(filename, 'wb') as f:\n",
    "   #     f.write(requests.get(link).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Extracción partes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definición de la carpeta donde se encuentran las sentencias\n",
    "files = os.listdir(\"./sentencias_completas/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Código para dividir las sentencias por partes según subtítulos de interés (Antecedentes; Consideraciones|Fundamentos; Decisión|Resuelve)\n",
    "sentdct = {}\n",
    "noencon = []\n",
    "for i,file in enumerate(files):\n",
    "    with open(str(\"./sentencias_completas/\"+files[i]), encoding=\"Windows-1252\", errors='ignore') as f:  \n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "        f.close()\n",
    "        btags = soup.find_all(\"b\")\n",
    "        trbtags = str(btags).replace(\"\\n\", \" \")\n",
    "        htags = soup.find_all(re.compile(\"h[0-9]|h\"))\n",
    "        trhtags = str(htags).replace(\"\\n\", \" \")\n",
    "        etags = soup.find_all(\"p\", class_=\"Estilo\")\n",
    "        tretags = str(etags).replace(\"\\n\", \" \")\n",
    "        mtags = soup.find_all(\"p\", class_=re.compile(\"MsoHeading[0-9]|MsoHeading\")) \n",
    "        trmtags = str(mtags).replace(\"\\n\", \" \")\n",
    "        ANT = re.findall(\"ANTECEDENTES|Antecedentes|A.N.T.E.C.E.D.E.N.T.E.S|A.n.t.e.c.e.d.e.n.t.e.s|INFORMACI.N|Informaci.n\", trbtags)\n",
    "        CONS = re.findall(\"CONSIDERACIONES|Consideraciones|FUNDAMENTO|Fundamento|F.U.N.D.A.M.E.N.T.O|F.u.n.d.a.m.e.n.t.o\", trbtags)\n",
    "        RES = re.findall(\"DECISI.N|Decisi.n|D.E.C.I.S.I...N|D.e.c.i.s.i...|RESUELVE|Resuelve|R.E.S.U.E.L.V.E|R.e.s.u.e.l.v.e\", trbtags)\n",
    "        ANT1 = re.findall(\"ANTECEDENTES|Antecedentes|A.N.T.E.C.E.D.E.N.T.E.S|A.n.t.e.c.e.d.e.n.t.e.s|INFORMACI.N|Informaci.n\", trhtags)\n",
    "        CONS1 = re.findall(\"CONSIDERACIONES|Consideraciones|FUNDAMENTO|Fundamento|F.U.N.D.A.M.E.N.T.O|F.u.n.d.a.m.e.n.t.o\", trhtags)\n",
    "        RES1 = re.findall(\"DECISI.N|Decisi.n|D.E.C.I.S.I...N|D.e.c.i.s.i...|RESUELVE|Resuelve|R.E.S.U.E.L.V.E|R.e.s.u.e.l.v.e\",trhtags)\n",
    "        ANT2 = re.findall(\"ANTECEDENTES|Antecedentes|A.N.T.E.C.E.D.E.N.T.E.S|A.n.t.e.c.e.d.e.n.t.e.s|INFORMACI.N|Informaci.n\", tretags)\n",
    "        CONS2 = re.findall(\"CONSIDERACIONES|Consideraciones|FUNDAMENTO|Fundamento|F.U.N.D.A.M.E.N.T.O|F.u.n.d.a.m.e.n.t.o\", tretags)\n",
    "        RES2 = re.findall(\"DECISI.N|Decisi.n|D.E.C.I.S.I...N|D.e.c.i.s.i...|RESUELVE|Resuelve|R.E.S.U.E.L.V.E|R.e.s.u.e.l.v.e\", tretags)\n",
    "        ANT3 = re.findall(\"ANTECEDENTES|Antecedentes|A.N.T.E.C.E.D.E.N.T.E.S|A.n.t.e.c.e.d.e.n.t.e.s|INFORMACI.N|Informaci.n\", trmtags)\n",
    "        CONS3 = re.findall(\"CONSIDERACIONES|Consideraciones|FUNDAMENTO|Fundamento|F.U.N.D.A.M.E.N.T.O|F.u.n.d.a.m.e.n.t.o\", trmtags)\n",
    "        RES3 = re.findall(\"DECISI.N|Decisi.n|D.E.C.I.S.I...N|D.e.c.i.s.i...|RESUELVE|Resuelve|R.E.S.U.E.L.V.E|R.e.s.u.e.l.v.e\", trmtags)\n",
    "        sent = re.findall(\"\\w+.\\d{3}-\\d{2}|\\w+.\\d{4}-\\d{2}|\\w+.\\d{3}\\w+-\\d{2}|\\w+.\\d{4}\\w+-\\d{2}\", str(soup))\n",
    "        if sent == []:\n",
    "            nsent = str(re.sub(\".htm\", \"\", files[i]))\n",
    "            noencon.append(\"identificador %s\" % (nsent))\n",
    "        else:\n",
    "            rawsent = str(re.sub(\".htm\", \"\", files[i]))\n",
    "            b = re.search(\"SU\", rawsent)\n",
    "            if b == None:\n",
    "                nsent = str(rawsent)\n",
    "            else:\n",
    "                nsent = str(re.sub(\"SU\", \"SU-\", rawsent))\n",
    "            DICTU = {\"id\":nsent}\n",
    "            ANTt = ANT + ANT1 + ANT2 + ANT3\n",
    "            CONSt = CONS + CONS1 + CONS2 + CONS3\n",
    "            RESt = RES + RES1 + RES2 + RES3\n",
    "            RESt.reverse()\n",
    "            with open(\"./sentencias_completas/\"+files[i], mode=\"r\", errors='ignore') as bigfile:\n",
    "                reader = bigfile.read()\n",
    "                text = reader.replace(\"\\n\", \" \")\n",
    "                bigfile.close()\n",
    "                if RESt != [] and CONSt != [] and ANTt != []:\n",
    "                    for i,part in enumerate(re.split(RESt[0], text, maxsplit=1)):\n",
    "                        with open(\"RESm_\" + str(i+1), mode=\"w\") as newfileres:\n",
    "                            newfileres.write(RESt[0]+part)\n",
    "                    repart1 = open(\"RESm_1\", \"r\")\n",
    "                    departr = open(\"RESm_2\", \"r\")\n",
    "                    DICTU[\"RES\"] = (departr.read())\n",
    "                    for i,part in enumerate(re.split(CONSt[0], repart1.read(), maxsplit=1)):\n",
    "                        with open(\"CONSm_\" + str(i+1), mode=\"w\") as newfilecons:\n",
    "                            newfilecons.write(CONSt[0]+part)\n",
    "                    repart2 = open(\"CONSm_1\", \"r\")\n",
    "                    departc = open(\"CONSm_2\", \"r\")\n",
    "                    DICTU[\"CUERPO\"] = (departc.read())\n",
    "                    for i,part in enumerate(re.split(ANTt[0], repart2.read(), maxsplit=1)):\n",
    "                        with open(\"ANTm_\" + str(i+1), mode=\"w\") as newfileant:\n",
    "                            newfileant.write(ANTt[0]+part)\n",
    "                    departh1 = open(\"ANTm_1\", \"r\")\n",
    "                    departh2 = open(\"ANTm_2\", \"r\")\n",
    "                    DICTU[\"ANT\"] = (departh2.read())\n",
    "                    DICTU[\"ENC\"] = (departh1.read())\n",
    "                elif RESt != [] and CONSt != [] and ANTt == []:\n",
    "                    for i,part in enumerate(re.split(RESt[0], reader, maxsplit=1)):\n",
    "                        with open(\"RESm_\" + str(i+1), mode=\"w\") as newfileres:\n",
    "                            newfileres.write(RESt[0]+part)\n",
    "                    repart1 = open(\"RESm_1\", \"r\")\n",
    "                    departr = open(\"RESm_2\", \"r\")\n",
    "                    DICTU[\"RES\"] = (departr.read())\n",
    "                    for i,part in enumerate(re.split(CONSt[0], repart1.read(), maxsplit=1)):\n",
    "                        with open(\"CONSm_\" + str(i+1), mode=\"w\") as newfilecons:\n",
    "                            newfilecons.write(CONSt[0]+part)\n",
    "                    repart2 = open(\"CONSm_1\", \"r\")\n",
    "                    departc = open(\"CONSm_2\", \"r\")\n",
    "                    DICTU[\"CUERPO\"] = (departc.read())\n",
    "                    DICTU[\"ENC\"] = (repart2.read())\n",
    "                elif RESt != [] and CONSt == [] and ANTt == []:\n",
    "                    for i,part in enumerate(re.split(RESt[0], reader, maxsplit=1)):\n",
    "                        with open(\"RESm_\" + str(i+1), mode=\"w\") as newfileres:\n",
    "                            newfileres.write(RESt[0]+part)\n",
    "                    repart1 = open(\"RESm_1\", \"r\")\n",
    "                    departr = open(\"RESm_2\", \"r\")\n",
    "                    DICTU[\"RES\"] = (departr.read())\n",
    "                    DICTU[\"CUERPO\"] = (repart1.read())\n",
    "                elif RESt != [] and CONSt == [] and ANTt != []:\n",
    "                    for i,part in enumerate(re.split(RESt[0], reader, maxsplit=1)):\n",
    "                        with open(\"RESm_\" + str(i+1), mode=\"w\") as newfileres:\n",
    "                            newfileres.write(RESt[0]+part)\n",
    "                    repart1 = open(\"RESm_1\", \"r\")\n",
    "                    departr = open(\"RESm_2\", \"r\")\n",
    "                    DICTU[\"RES\"] = (departr.read())\n",
    "                    DICTU[\"CUERPO\"] = (repart1.read())\n",
    "                else:\n",
    "                    DICTU[\"CUERPO\"] = text\n",
    "                    print(\"%s_error5\" % (nsent))\n",
    "            sentdct['%s' % (nsent)] = DICTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(noencon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recolección de precedentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listas necesarias para mantener el mismo formato de años\n",
    "nyears = [\"1991\", \"1992\", \"1993\", \"1994\", \"1995\", \"1996\", \"1997\", \"1998\", \"1999\"]\n",
    "dyears = [\"2000\", \"2001\", \"2002\", \"2003\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código que extrae los precedentes de cada sentencia según la parte de interés (Cuerpo: Consideraciones|Fundamentos y su respectivos pies de página)\n",
    "# ardict es el diccionario que contiene cada identificador de la sentencia (ID) con sus conexiones (precedentes)\n",
    "# Label es la etiqueta para utilizar en Gephi y Tipo es el tipo de sentencia para poder filtrar en la red\n",
    "netdict = {}\n",
    "conexiones = []\n",
    "ids = []\n",
    "tipos = []\n",
    "for key in sentdct.keys():\n",
    "    pint1 = sentdct[key].get(\"CUERPO\")\n",
    "    soupcu = BeautifulSoup(pint1, \"html.parser\")\n",
    "    results1 = soupcu.find_all(\"a\")\n",
    "    pint2 = sentdct[key].get(\"RES\")\n",
    "    precedentes = []\n",
    "    precedentesf = []\n",
    "    if pint2 != None:\n",
    "        soupres = BeautifulSoup(pint2, \"html.parser\")\n",
    "        results2 = soupres.find_all(\"p\", class_= \"MsoFootnoteText\")\n",
    "        footname1 = [] \n",
    "        footname2 = []\n",
    "        clearnames = []\n",
    "        resultsdef = []\n",
    "        for result1 in results1:\n",
    "            footname1.append(result1.get(\"href\"))\n",
    "        for foot in footname1:\n",
    "            if foot != None:\n",
    "                clearnames.append(foot.replace(\"#\", \"\"))\n",
    "        for result2 in results2:\n",
    "            apart = result2.find(\"a\")\n",
    "            if apart != None:\n",
    "                name = apart.get(\"name\")\n",
    "                for clearname in clearnames:\n",
    "                    if name == clearname:\n",
    "                        resultsdef.append(result2)\n",
    "        format1c = re.findall(\"(C|T|SU)[-| ](\\d+A|\\d+) \\w+ \\d+ de \\w+ \\w+ (\\d+)\", pint1)\n",
    "        for f1c in format1c:\n",
    "            ele = list(f1c)\n",
    "            eled = []\n",
    "            for e in ele: \n",
    "                if e in nyears:\n",
    "                    eled.append(re.sub(\"19\", \"\", e))\n",
    "                if e in dyears:\n",
    "                    eled.append(re.sub(\"20\", \"\", e))\n",
    "                else:\n",
    "                    eled.append(e)\n",
    "            if len(eled) >= 4:\n",
    "                eled.pop()\n",
    "            precedentes.append(\"-\".join(eled))\n",
    "        format1r = re.findall(\"(C|T|SU)[-| ](\\d+A|\\d+) \\w+ \\d+ de \\w+ \\w+ (\\d+)\", str(resultsdef))\n",
    "        for f1r in format1r:\n",
    "            ele = list(f1r)\n",
    "            eled = []\n",
    "            for e in ele: \n",
    "                if e in nyears:\n",
    "                    eled.append(re.sub(\"19\", \"\", e))\n",
    "                if e in dyears:\n",
    "                    eled.append(re.sub(\"20\", \"\", e))\n",
    "                else:\n",
    "                    eled.append(e)\n",
    "            if len(eled) >= 4:\n",
    "                eled.pop()\n",
    "            precedentes.append(\"-\".join(eled))\n",
    "        format2c = re.findall(\"(C|T|SU)[-| ](\\d+A|\\d+)/(\\d+)\", pint1)\n",
    "        for f2c in format2c:\n",
    "            ele = list(f2c)\n",
    "            eled = []\n",
    "            for e in ele: \n",
    "                if e in nyears:\n",
    "                    eled.append(re.sub(\"19\", \"\", e))\n",
    "                if e in dyears:\n",
    "                    eled.append(re.sub(\"20\", \"\", e))\n",
    "                else:\n",
    "                    eled.append(e)\n",
    "            if len(eled) >= 4:\n",
    "                eled.pop()\n",
    "            precedentes.append(\"-\".join(eled))\n",
    "        format2r = re.findall(\"(C|T|SU)[-| ](\\d+A|\\d+)/(\\d+)\", str(resultsdef))\n",
    "        for f2r in format2r:\n",
    "            ele = list(f2r)\n",
    "            eled = []\n",
    "            for e in ele: \n",
    "                if e in nyears:\n",
    "                    eled.append(re.sub(\"19\", \"\", e))\n",
    "                if e in dyears:\n",
    "                    eled.append(re.sub(\"20\", \"\", e))\n",
    "                else:\n",
    "                    eled.append(e)\n",
    "            if len(eled) >= 4:\n",
    "                eled.pop()\n",
    "            precedentes.append(\"-\".join(eled))\n",
    "        format3c = re.findall(\"(C|T|SU)[-| ](\\d+) \\w+ ([0-9][0-9][0-9][0-9])\", pint1)\n",
    "        for f3c in format3c:\n",
    "            ele = list(f3c)\n",
    "            eled = []\n",
    "            for e in ele: \n",
    "                if e in nyears:\n",
    "                    eled.append(re.sub(\"19\", \"\", e))\n",
    "                if e in dyears:\n",
    "                    eled.append(re.sub(\"20\", \"\", e))\n",
    "                else:\n",
    "                    eled.append(e)\n",
    "            if len(eled) >= 4:\n",
    "                eled.pop()\n",
    "            precedentes.append(\"-\".join(eled))\n",
    "        format3r = re.findall(\"(C|T|SU)[-| ](\\d+) \\w+ ([0-9][0-9][0-9][0-9])\", str(resultsdef))\n",
    "        for f3r in format3r:\n",
    "            ele = list(f3r)\n",
    "            eled = []\n",
    "            for e in ele: \n",
    "                if e in nyears:\n",
    "                    eled.append(re.sub(\"19\", \"\", e))\n",
    "                if e in dyears:\n",
    "                    eled.append(re.sub(\"20\", \"\", e))\n",
    "                else:\n",
    "                    eled.append(e)\n",
    "            if len(eled) >= 4:\n",
    "                eled.pop()\n",
    "            precedentes.append(\"-\".join(eled))\n",
    "    if pint2 == None:\n",
    "        format1c = re.findall(\"(C|T|SU)[-| ](\\d+A|\\d+) \\w+ \\d+ de \\w+ \\w+ (\\d+)\", pint1)\n",
    "        for f1c in format1c:\n",
    "            ele = list(f1c)\n",
    "            eled = []\n",
    "            for e in ele: \n",
    "                if e in nyears:\n",
    "                    eled.append(re.sub(\"19\", \"\", e))\n",
    "                if e in dyears:\n",
    "                    eled.append(re.sub(\"20\", \"\", e))\n",
    "                else:\n",
    "                    eled.append(e)\n",
    "            if len(eled) >= 4:\n",
    "                eled.pop()\n",
    "            precedentes.append(\"-\".join(eled))\n",
    "        format2c = re.findall(\"(C|T|SU)[-| ](\\d+A|\\d+)/(\\d+)\", pint1)\n",
    "        for f2c in format2c:\n",
    "            ele = list(f2c)\n",
    "            eled = []\n",
    "            for e in ele: \n",
    "                if e in nyears:\n",
    "                    eled.append(re.sub(\"19\", \"\", e))\n",
    "                if e in dyears:\n",
    "                    eled.append(re.sub(\"20\", \"\", e))\n",
    "                else:\n",
    "                    eled.append(e)\n",
    "            if len(eled) >= 4:\n",
    "                eled.pop()\n",
    "            precedentes.append(\"-\".join(eled))\n",
    "        format3c = re.findall(\"(C|T|SU)[-| ](\\d+) \\w+ ([0-9][0-9][0-9][0-9])\", pint1)\n",
    "        for f3c in format3c:\n",
    "            ele = list(f3c)\n",
    "            eled = []\n",
    "            for e in ele:\n",
    "                if e in nyears:\n",
    "                    eled.append(re.sub(\"19\", \"\", e))\n",
    "                if e in dyears:\n",
    "                    eled.append(re.sub(\"20\", \"\", e))\n",
    "                else:\n",
    "                    eled.append(e)\n",
    "            if len(eled) >= 4:\n",
    "                eled.pop()\n",
    "            precedentes.append(\"-\".join(eled))\n",
    "    precedentesf = re.findall(\"\\w+-\\d{3}-\\d{2}|\\w+-\\d{4}-\\d{2}|\\w+-\\d{3}A-\\d{2}|\\w+-\\d{4}A-\\d{2}\", str(precedentes))\n",
    "    ids.append(key)\n",
    "    conexiones.append(precedentesf)\n",
    "    tipos.append(key[0])\n",
    "netdict[\"Label\"] = ids\n",
    "netdict[\"Tipo\"] = tipos\n",
    "netdict[\"Id\"] = ids\n",
    "netdict[\"conexiones\"] = conexiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(netdict[\"Id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformación de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de nodos y arcos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación del dataframe de nodos\n",
    "nodos = pd.DataFrame(netdict)\n",
    "nodos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación de cada conexión entre sentencias para que sea una a una\n",
    "sources = []\n",
    "target = []\n",
    "for i in range(len(nodos)):\n",
    "    conexiones = nodos[\"conexiones\"].values[i]\n",
    "    for j in range(len(conexiones)):\n",
    "        sources.append(nodos[\"Id\"].values[i])\n",
    "        target.append(conexiones[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación del dataframe de arcos, donde hay una entrada para cada sentencia (source) que cita a otra (target)\n",
    "arcos = pd.DataFrame(list(zip(sources, target)), \n",
    "               columns =['Source', 'Target'])\n",
    "arcos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportación a excel sin columna de index para facilitar el paso al programa Ghepi\n",
    "arcos.to_excel(\"arcos.xlsx\", index = None)\n",
    "nodos.to_excel(\"nodos.xlsx\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportación a formato de separación por comas\n",
    "nodos.to_csv(\"nodos_vf.csv\", index = None)\n",
    "arcos.to_csv(\"arcos_vf.csv\", index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para crear la red con los archivos omitiendo los pasos anteriores\n",
    "nodos = pd.read_csv('nodos_vf.csv', sep=',')\n",
    "arcos = pd.read_csv('arcos_vf.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de la red dirigida, según los dataframes de nodos y arcos\n",
    "G = nx.DiGraph()\n",
    "\n",
    "#Adicionar los nodos y sus atributos a la red\n",
    "for i in range(len(nodos['Id'])):   \n",
    "    G.add_node(nodos['Id'][i])\n",
    "    for j in nodos:\n",
    "        if j!= 'Id':\n",
    "            G.nodes[nodos['Id'][i]][j]=nodos[j][i]\n",
    "            \n",
    "            \n",
    "# Adicionar los arcos de la red\n",
    "for i in range(len(arcos['Source'])):\n",
    "    G.add_edge(arcos['Source'][i],arcos['Target'][i])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para observar el número total de arcos y nodos\n",
    "print(G.number_of_edges())\n",
    "print(G.number_of_nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeros acercamientos al análisis de redes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráfico de la red (costoso en términos de tiempo)\n",
    "fig=plt.figure(figsize=(100,100))\n",
    "\n",
    "# Después se genera el gráfico\n",
    "k = nx.draw(G, node_size=50, node_color='lightgreen', edge_color='lightgray', with_labels=False)\n",
    "plt.axis(\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distrucion del grado\n",
    "grado=[]\n",
    "for node in G.nodes():\n",
    "    grado.append(G.degree(node))\n",
    "    \n",
    "# Histograma\n",
    "a=plt.hist(grado)\n",
    "plt.title('Histograma del grado de la red')\n",
    "plt.xlabel (\"Grado k\")\n",
    "plt.ylabel (\"N(k)\")\n",
    "plt.show()\n",
    "\n",
    "# Distribución\n",
    "degree_freq = nx.degree_histogram(G)\n",
    "degrees = range(len(degree_freq))\n",
    "plt.loglog(degrees, degree_freq, 'o') \n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribución logarítmica del grado de la red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para conocer las sentencia más conectada\n",
    "dic_grados=G.in_degree()\n",
    "mas_conectado=''\n",
    "max_grado = 0\n",
    "for i,values_i in dic_grados:\n",
    "    if values_i > max_grado:\n",
    "        max_grado=values_i\n",
    "        mas_conectado=G.nodes[i]['Label']\n",
    "        \n",
    "print('El nodo más conectado es', mas_conectado, 'con un grado de', max_grado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista con las 10 sentencias más citadas\n",
    "sorted_deg =  sorted(dic_grados, key=lambda item: item[1], reverse=True)\n",
    "pd.DataFrame(sorted_deg[0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Promedio del grado de entrada\n",
    "degrees = []\n",
    "for n in G.nodes():\n",
    "    degrees.append(G.in_degree(n))\n",
    "np.mean(degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Densidad de la red\n",
    "nx.density(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detección de comunidades (No se ha probado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCommunities(G):\n",
    "    \"\"\"\n",
    "    Partition network with the Infomap algorithm.\n",
    "    Annotates nodes with 'community' id and return number of communities found.\n",
    "    \"\"\"\n",
    "    infomapX = infomap.Infomap(\"--two-level\")\n",
    "\n",
    "    print(\"Building Infomap network from a NetworkX graph...\")\n",
    "    for e in G.edges():\n",
    "        infomapX.network().addLink(*e)\n",
    "\n",
    "    print(\"Find communities with Infomap...\")\n",
    "    infomapX.run();\n",
    "\n",
    "    print(\"Found {} modules with codelength: {}\".format(infomapX.numTopModules(), infomapX.codelength()))\n",
    "\n",
    "    communities = {}\n",
    "    for node in infomapX.iterLeafNodes():\n",
    "        communities[node.physicalId] = node.moduleIndex()\n",
    "\n",
    "    nx.set_node_attributes(G, values=communities, name='community')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawNetwork(G):\n",
    "    # position map\n",
    "    pos = nx.spring_layout(G)\n",
    "    # community ids\n",
    "    communities = [v for k,v in nx.get_node_attributes(G, 'community').items()]\n",
    "    numCommunities = max(communities) + 1\n",
    "    # color map from http://colorbrewer2.org/\n",
    "    cmapLight = colors.ListedColormap(['#a6cee3', '#b2df8a', '#fb9a99', '#fdbf6f', '#cab2d6'], 'indexed', numCommunities)\n",
    "    cmapDark = colors.ListedColormap(['#1f78b4', '#33a02c', '#e31a1c', '#ff7f00', '#6a3d9a'], 'indexed', numCommunities)\n",
    "\n",
    "    # Draw edges\n",
    "    nx.draw_networkx_edges(G, pos)\n",
    "\n",
    "    # Draw nodes\n",
    "    nodeCollection = nx.draw_networkx_nodes(G,\n",
    "        pos = pos,\n",
    "        node_color = communities,\n",
    "        cmap = cmapLight\n",
    "    )\n",
    "    # Set node border color to the darker shade\n",
    "    darkColors = [cmapDark(v) for v in communities]\n",
    "    nodeCollection.set_edgecolor(darkColors)\n",
    "\n",
    "    # Draw node labels\n",
    "    for n in G.nodes():\n",
    "        plt.annotate(n,\n",
    "            xy = pos[n],\n",
    "            textcoords = 'offset points',\n",
    "            horizontalalignment = 'center',\n",
    "            verticalalignment = 'center',\n",
    "            xytext = [0, 0],\n",
    "            color = cmapDark(communities[n])\n",
    "        )\n",
    "\n",
    "    plt.axis('off')\n",
    "    # plt.savefig(\"karate.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findCommunities(K)\n",
    "\n",
    "drawNetwork(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P= nx.to_undirected(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = community.best_partition(P)\n",
    "values = [partition.get(node) for node in P.nodes()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spring_pos=nx.spring_layout(P)\n",
    "plt.figure(figsize=(10,10))\n",
    "nx.draw(P,pos=spring_pos,node_color = values, node_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para hacer pruebas, no usar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Códigos para hacer pruebas individuales a cada sentencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentdct = {}\n",
    "noencon = []\n",
    "with open(str(\"./sentencias_completas/\"+files[1]), encoding=\"Windows-1252\") as f:   \n",
    "    soup = BeautifulSoup(f, \"html.parser\")\n",
    "    f.close()\n",
    "    btags = soup.find_all(\"b\")\n",
    "    htags = soup.find_all(re.compile(\"h[0-9]|h\"))\n",
    "    etags = soup.find_all(\"p\", class_=\"Estilo\")\n",
    "    mtags = soup.find_all(\"p\", class_=re.compile(\"MsoHeading[0-9]|MsoHeading\"))    \n",
    "    ANT = re.findall(\"ANTECEDENTES|Antecedentes|A.N.T.E.C.E.D.E.N.T.E.S|A.n.t.e.c.e.d.e.n.t.e.s|INFORMACI.N|Informaci.n\", str(btags))\n",
    "    CONS = re.findall(\"CONSIDERACIONES|Consideraciones|FUNDAMENTO|Fundamento|F.U.N.D.A.M.E.N.T.O|F.u.n.d.a.m.e.n.t.o\", str(btags))\n",
    "    RES = re.findall(\"DECISI.N|Decisi.n|D.E.C.I.S.I...N|D.e.c.i.s.i...|RESUELVE|Resuelve|R.E.S.U.E.L.V.E|R.e.s.u.e.l.v.e|R\\nE.S.U.E.L.V.E|R\\ne.s.u.e.l.v.e\", str(btags))\n",
    "    ANT1 = re.findall(\"ANTECEDENTES|Antecedentes|A.N.T.E.C.E.D.E.N.T.E.S|A.n.t.e.c.e.d.e.n.t.e.s|INFORMACI.N|Informaci.n\", str(htags))\n",
    "    CONS1 = re.findall(\"CONSIDERACIONES|Consideraciones|FUNDAMENTO|Fundamento|F.U.N.D.A.M.E.N.T.O|F.u.n.d.a.m.e.n.t.o\", str(htags))\n",
    "    RES1 = re.findall(\"DECISI.N|Decisi.n|D.E.C.I.S.I...N|D.e.c.i.s.i...|RESUELVE|Resuelve|R.E.S.U.E.L.V.E|R.e.s.u.e.l.v.e|R\\nE.S.U.E.L.V.E|R\\ne.s.u.e.l.v.e\", str(htags))\n",
    "    ANT2 = re.findall(\"ANTECEDENTES|Antecedentes|A.N.T.E.C.E.D.E.N.T.E.S|A.n.t.e.c.e.d.e.n.t.e.s|INFORMACI.N|Informaci.n\", str(etags))\n",
    "    CONS2 = re.findall(\"CONSIDERACIONES|Consideraciones|FUNDAMENTO|Fundamento|F.U.N.D.A.M.E.N.T.O|F.u.n.d.a.m.e.n.t.o\", str(etags))\n",
    "    RES2 = re.findall(\"DECISI.N|Decisi.n|D.E.C.I.S.I...N|D.e.c.i.s.i...|RESUELVE|Resuelve|R.E.S.U.E.L.V.E|R.e.s.u.e.l.v.e|R\\nE.S.U.E.L.V.E|R\\ne.s.u.e.l.v.e\", str(etags))\n",
    "    ANT3 = re.findall(\"ANTECEDENTES|Antecedentes|A.N.T.E.C.E.D.E.N.T.E.S|A.n.t.e.c.e.d.e.n.t.e.s|INFORMACI.N|Informaci.n\", str(mtags))\n",
    "    CONS3 = re.findall(\"CONSIDERACIONES|Consideraciones|FUNDAMENTO|Fundamento|F.U.N.D.A.M.E.N.T.O|F.u.n.d.a.m.e.n.t.o\", str(mtags))\n",
    "    RES3 = re.findall(\"DECISI.N|Decisi.n|D.E.C.I.S.I...N|D.e.c.i.s.i...|RESUELVE|Resuelve|R.E.S.U.E.L.V.E|R.e.s.u.e.l.v.e|R\\nE.S.U.E.L.V.E|R\\ne.s.u.e.l.v.e\", str(mtags))\n",
    "    sent = re.findall(\"([CcTtSs].[0-9][0-9][0-9]-[0-9][0-9]|[CcTtSs].[0-9][0-9][0-9][Aa]-[0-9][0-9]|[CcTtSs].[0-9][0-9][0-9][0-9]-[0-9][0-9]|[CcTtSs].[0-9][0-9][0-9][0-9][Aa]-[0-9][0-9])\", str(soup))\n",
    "    if sent == []:\n",
    "        noencon.append(\"identificador %d\" % (i))\n",
    "    else:\n",
    "        rawsent = str(re.sub(\".htm\", \"\", files[1]))\n",
    "        b = re.search(\"SU\", rawsent)\n",
    "        if b == None:\n",
    "            nsent = str(rawsent)\n",
    "        else:\n",
    "            nsent = str(re.sub(\"SU\", \"SU-\", rawsent))\n",
    "        DICTU = {\"id\":nsent}\n",
    "        ANTt = ANT + ANT1 + ANT2 + ANT3\n",
    "        CONSt = CONS + CONS1 + CONS2 + CONS3\n",
    "        RESt = RES + RES1 + RES2 + RES3\n",
    "        RESt.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./sample_sentencias/\"+files[3], mode=\"r\") as bigfile:\n",
    "    reader = bigfile.read()\n",
    "    bigfile.close()\n",
    "    if RESt != [] and CONSt != [] and ANTt != []:\n",
    "        for i,part in enumerate(re.split(RESt[0], reader, maxsplit=1)):\n",
    "            with open(\"RESm_\" + str(i+1), mode=\"w\") as newfileres:\n",
    "                newfileres.write(RESt[0]+part)\n",
    "        repart1 = open(\"RESm_1\", \"r\")\n",
    "        departr = open(\"RESm_2\", \"r\")\n",
    "        DICTU[\"RES\"] = (departr.read())\n",
    "        for i,part in enumerate(re.split(CONSt[0], repart1.read(), maxsplit=1)):\n",
    "            with open(\"CONSm_\" + str(i+1), mode=\"w\") as newfilecons:\n",
    "                newfilecons.write(CONSt[0]+part)\n",
    "        repart2 = open(\"CONSm_1\", \"r\")\n",
    "        departc = open(\"CONSm_2\", \"r\")\n",
    "        DICTU[\"CONS\"] = (departc.read())\n",
    "        for i,part in enumerate(re.split(ANTt[0], repart2.read(), maxsplit=1)):\n",
    "             with open(\"ANTm_\" + str(i+1), mode=\"w\") as newfileant:\n",
    "                newfileant.write(ANTt[0]+part)\n",
    "        departh1 = open(\"ANTm_1\", \"r\")\n",
    "        departh2 = open(\"ANTm_2\", \"r\")\n",
    "        DICTU[\"ANT\"] = (departh2.read())\n",
    "        DICTU[\"ENC\"] = (departh1.read())\n",
    "    elif RESt != [] and CONSt != [] and ANTt == []:\n",
    "        for i,part in enumerate(re.split(RESt[0], reader, maxsplit=1)):\n",
    "            with open(\"RESm_\" + str(i+1), mode=\"w\") as newfileres:\n",
    "                newfileres.write(RESt[0]+part)\n",
    "        repart1 = open(\"RESm_1\", \"r\")\n",
    "        departr = open(\"RESm_2\", \"r\")\n",
    "        DICTU[\"RES\"] = (departr.read())\n",
    "        for i,part in enumerate(re.split(CONSt[0], repart1.read(), maxsplit=1)):\n",
    "            with open(\"CONSm_\" + str(i+1), mode=\"w\") as newfilecons:\n",
    "                newfilecons.write(CONSt[0]+part)\n",
    "        repart2 = open(\"CONSm_1\", \"r\")\n",
    "        departc = open(\"CONSm_2\", \"r\")\n",
    "        DICTU[\"CONS\"] = (departc.read())\n",
    "        DICTU[\"ENC\"] = (repart2.read())\n",
    "    elif RESt != [] and CONSt == [] and ANTt == []:\n",
    "        for i,part in enumerate(re.split(RESt[0], reader, maxsplit=1)):\n",
    "            with open(\"RESm_\" + str(i+1), mode=\"w\") as newfileres:\n",
    "                newfileres.write(RESt[0]+part)\n",
    "        repart1 = open(\"RESm_1\", \"r\")\n",
    "        departr = open(\"RESm_2\", \"r\")\n",
    "        DICTU[\"RES\"] = (departr.read())\n",
    "        DICTU[\"CUERPO\"] = (repart1.read())\n",
    "    elif RESt != [] and CONSt == [] and ANTt != []:\n",
    "        print(\"%s_error4\" % (nsent))\n",
    "    else:\n",
    "        print(\"%s_error5\" % (nsent))\n",
    "sentdct['%s' % (nsent)] = DICTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ardict = {}\n",
    "pint1 = sentdct[\"C-1195-01\"].get(\"CUERPO\")\n",
    "pint2 = sentdct[\"C-1195-01\"].get(\"RES\")\n",
    "soupcu = BeautifulSoup(pint1, \"html.parser\")\n",
    "soupres = BeautifulSoup(pint2, \"html.parser\")\n",
    "results1 = soupcu.find_all(\"a\")\n",
    "results2 = soupres.find_all(\"p\", class_= \"MsoFootnoteText\")\n",
    "precedentes = []\n",
    "if results2 != []:\n",
    "    footname1 = [] \n",
    "    footname2 = []\n",
    "    clearnames = []\n",
    "    resultsdef = []\n",
    "    for result1 in results1:\n",
    "        footname1.append(result1.get(\"href\"))\n",
    "    for foot in footname1:\n",
    "        if foot != None:\n",
    "            clearnames.append(foot.replace(\"#\", \"\"))\n",
    "    for result2 in results2:\n",
    "        apart = result2.find(\"a\")\n",
    "        if apart != None:\n",
    "            name = apart.get(\"name\")\n",
    "            for clearname in clearnames:\n",
    "                if name == clearname:\n",
    "                    resultsdef.append(result2)\n",
    "    format1c = re.findall(\"(C|T|S)[-| ](\\d+A|\\d+) del [0-9][0-9] de \\w+ de (\\d+)\", pint1)\n",
    "    for f1c in format1c:\n",
    "        ele = list(f1c)\n",
    "        eled = []\n",
    "        for e in ele: \n",
    "            if e in nyears:\n",
    "                eled.append(re.sub(\"19\", \"\", e))\n",
    "            if e in dyears:\n",
    "                eled.append(re.sub(\"20\", \"\", e))\n",
    "            else:\n",
    "                eled.append(e)\n",
    "        if len(eled) >= 4:\n",
    "            eled.pop()\n",
    "        precedentes.append(\"-\".join(eled))\n",
    "    format1r = re.findall(\"(C|T|S)[-| ](\\d+A|\\d+) del [0-9][0-9] de \\w+ de (\\d+)\", pint2)\n",
    "    for f1r in format1r:\n",
    "        ele = list(f1r)\n",
    "        eled = []\n",
    "        for e in ele: \n",
    "            if e in nyears:\n",
    "                eled.append(re.sub(\"19\", \"\", e))\n",
    "            if e in dyears:\n",
    "                eled.append(re.sub(\"20\", \"\", e))\n",
    "            else:\n",
    "                eled.append(e)\n",
    "        if len(eled) >= 4:\n",
    "            eled.pop()\n",
    "        precedentes.append(\"-\".join(eled))\n",
    "    format2c = re.findall(\"(C|T|S)[-| ](\\d+A|\\d+)/(\\d+)\", pint1)\n",
    "    for f2c in format2c:\n",
    "        ele = list(f2c)\n",
    "        eled = []\n",
    "        for e in ele: \n",
    "            if e in nyears:\n",
    "                eled.append(re.sub(\"19\", \"\", e))\n",
    "            if e in dyears:\n",
    "                eled.append(re.sub(\"20\", \"\", e))\n",
    "            else:\n",
    "                eled.append(e)\n",
    "        if len(eled) >= 4:\n",
    "            eled.pop()\n",
    "        precedentes.append(\"-\".join(eled))\n",
    "    format2r = re.findall(\"(C|T|S)[-| ](\\d+A|\\d+)/(\\d+)\", str(resultsdef))\n",
    "    for f2r in format2r:\n",
    "        ele = list(f2r)\n",
    "        eled = []\n",
    "        for e in ele: \n",
    "            if e in nyears:\n",
    "                eled.append(re.sub(\"19\", \"\", e))\n",
    "            if e in dyears:\n",
    "                eled.append(re.sub(\"20\", \"\", e))\n",
    "            else:\n",
    "                eled.append(e)\n",
    "        if len(eled) >= 4:\n",
    "            eled.pop()\n",
    "        precedentes.append(\"-\".join(eled))\n",
    "    format3c = re.findall(\"(C|T|S)[-| ](\\d+A|\\d+) d[e|el] (\\d+)\", pint1)\n",
    "    for f3c in format3c:\n",
    "        ele = list(f3c)\n",
    "        eled = []\n",
    "        for e in ele: \n",
    "            if e in nyears:\n",
    "                eled.append(re.sub(\"19\", \"\", e))\n",
    "            if e in dyears:\n",
    "                eled.append(re.sub(\"20\", \"\", e))\n",
    "            else:\n",
    "                eled.append(e)\n",
    "        if len(eled) >= 4:\n",
    "            eled.pop()\n",
    "        precedentes.append(\"-\".join(eled))\n",
    "    format3r = re.findall(\"(C|T|S)[-| ](\\d+A|\\d+) d[e|el] (\\d+)\", str(resultsdef))\n",
    "    for f3r in format3r:\n",
    "        ele = list(f3r)\n",
    "        eled = []\n",
    "        for e in ele: \n",
    "            if e in nyears:\n",
    "                eled.append(re.sub(\"19\", \"\", e))\n",
    "            if e in dyears:\n",
    "                eled.append(re.sub(\"20\", \"\", e))\n",
    "            else:\n",
    "                eled.append(e)\n",
    "        if len(eled) >= 4:\n",
    "            eled.pop()\n",
    "        precedentes.append(\"-\".join(eled))\n",
    "if results2 == []:\n",
    "    format1c = re.findall(\"(C|T|S)[-| ](\\d+A|\\d+) del [0-9][0-9] de \\w+ de (\\d+)\", pint1)\n",
    "    for f1c in format1c:\n",
    "        ele = list(f1c)\n",
    "        eled = []\n",
    "        for e in ele: \n",
    "            if e in nyears:\n",
    "                eled.append(re.sub(\"19\", \"\", e))\n",
    "            if e in dyears:\n",
    "                eled.append(re.sub(\"20\", \"\", e))\n",
    "            else:\n",
    "                eled.append(e)\n",
    "        if len(eled) >= 4:\n",
    "            eled.pop()\n",
    "        precedentes.append(\"-\".join(eled))\n",
    "    format2c = re.findall(\"(C|T|S)[-| ](\\d+A|\\d+)/(\\d+)\", pint1)\n",
    "    for f2c in format2c:\n",
    "        ele = list(f2c)\n",
    "        eled = []\n",
    "        for e in ele: \n",
    "            if e in nyears:\n",
    "                eled.append(re.sub(\"19\", \"\", e))\n",
    "            if e in dyears:\n",
    "                eled.append(re.sub(\"20\", \"\", e))\n",
    "            else:\n",
    "                eled.append(e)\n",
    "        if len(eled) >= 4:\n",
    "            eled.pop()\n",
    "        precedentes.append(\"-\".join(eled))\n",
    "    format3c = re.findall(\"(C|T|S)[-| ](\\d+A|\\d+) d[e|el] (\\d+)\", pint1)\n",
    "    for f3c in format3c:\n",
    "        ele = list(f3c)\n",
    "        eled = []\n",
    "        for e in ele: \n",
    "            if e in nyears:\n",
    "                eled.append(re.sub(\"19\", \"\", e))\n",
    "            if e in dyears:\n",
    "                eled.append(re.sub(\"20\", \"\", e))\n",
    "            else:\n",
    "                eled.append(e)\n",
    "        if len(eled) >= 4:\n",
    "            eled.pop()\n",
    "        precedentes.append(\"-\".join(eled))\n",
    "precedentesf = re.findall(\"[C|T|SU]-\\d{3}-\\d{2}|[C|T|SU]-\\d{4}-\\d{2}\", str(precedentes))\n",
    "ardict[\"sent\"] = precedentesf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
